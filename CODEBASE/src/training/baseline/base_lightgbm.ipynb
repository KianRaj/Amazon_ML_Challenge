{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-12T16:38:57.689057Z",
     "iopub.status.busy": "2025-10-12T16:38:57.688880Z",
     "iopub.status.idle": "2025-10-12T16:39:03.055870Z",
     "shell.execute_reply": "2025-10-12T16:39:03.055001Z",
     "shell.execute_reply.started": "2025-10-12T16:38:57.689039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully!\n",
      "   sample_id                                    catalog_content  \\\n",
      "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
      "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
      "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
      "3      55858  Item Name: Judeeâ€™s Blue Cheese Powder 11.25 oz...   \n",
      "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
      "\n",
      "                                          image_link  price  \n",
      "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
      "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
      "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
      "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
      "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = '../../../dataset/train.csv'\n",
    "test_path = '../../../dataset/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path) \n",
    "    \n",
    "print(\"Training data loaded successfully!\")\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:39:07.551049Z",
     "iopub.status.busy": "2025-10-12T16:39:07.550767Z",
     "iopub.status.idle": "2025-10-12T16:39:15.691437Z",
     "shell.execute_reply": "2025-10-12T16:39:15.690582Z",
     "shell.execute_reply.started": "2025-10-12T16:39:07.551028Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering complete.\n",
      "   ipq  quantity_oz                                       cleaned_text\n",
      "0    6        12.00   la victoria green taco sauce mild 12 ounce pa...\n",
      "1    4         8.00   salerno cookies the original butter cookies 8...\n",
      "2    6         1.90   bear creek hearty soup bowl creamy chicken wi...\n",
      "3    1        11.25   judees blue cheese powder 1125 oz  glutenfree...\n",
      "4   12        12.70   kedem sherry cooking wine 127 ounce  12 per c...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/student-resource/student_resource/dataset/train.csv')\n",
    "\n",
    "\n",
    "def extract_ipq(text):\n",
    "    match = re.search(r'\\(Pack of (\\d+)\\)|(\\d+) per case|PK- (\\d+)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(next(item for item in match.groups() if item is not None))\n",
    "    return 1\n",
    "\n",
    "def extract_quantity_oz(text):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*(Ounce|Oz|Pound)', str(text), re.IGNORECASE)\n",
    "    if match:\n",
    "        value = float(match.group(1))\n",
    "        unit = match.group(2).lower()\n",
    "        if 'pound' in unit:\n",
    "            return value * 16\n",
    "        return value\n",
    "    return \n",
    "\n",
    "df['ipq'] = df['catalog_content'].apply(extract_ipq)\n",
    "df['quantity_oz'] = df['catalog_content'].apply(extract_quantity_oz)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'item name:|bullet point \\d+:', '', text) \n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text) \n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['catalog_content'].apply(clean_text)\n",
    "\n",
    "print(\"Feature engineering complete.\")\n",
    "print(df[['ipq', 'quantity_oz', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:39:33.197080Z",
     "iopub.status.busy": "2025-10-12T16:39:33.196804Z",
     "iopub.status.idle": "2025-10-12T16:39:40.861753Z",
     "shell.execute_reply": "2025-10-12T16:39:40.860849Z",
     "shell.execute_reply.started": "2025-10-12T16:39:33.197063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text features...\n",
      "Combining text and numerical features...\n",
      "\n",
      "Data preparation complete.\n",
      "Shape of our final feature matrix (X): (75000, 5002)\n",
      "Shape of our final target vector (y): (75000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "text_features = vectorizer.fit_transform(df['cleaned_text'])\n",
    "numerical_features = df[['ipq', 'quantity_oz']].values\n",
    "X = hstack([text_features, csr_matrix(numerical_features)])\n",
    "y = np.log1p(df['price'])\n",
    "\n",
    "print(f\"Shape of our final feature matrix (X): {X.shape}\")\n",
    "print(f\"Shape of our final target vector (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:39:48.193276Z",
     "iopub.status.busy": "2025-10-12T16:39:48.192128Z",
     "iopub.status.idle": "2025-10-12T16:39:48.319918Z",
     "shell.execute_reply": "2025-10-12T16:39:48.319240Z",
     "shell.execute_reply.started": "2025-10-12T16:39:48.193238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting complete.\n",
      "Training features shape: (60000, 5002)\n",
      "Validation features shape: (15000, 5002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:40:03.459407Z",
     "iopub.status.busy": "2025-10-12T16:40:03.459131Z",
     "iopub.status.idle": "2025-10-12T16:44:28.385875Z",
     "shell.execute_reply": "2025-10-12T16:44:28.382678Z",
     "shell.execute_reply.started": "2025-10-12T16:40:03.459388Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM model...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's rmse: 0.719153\n",
      "\n",
      "Evaluating model performance...\n",
      "\n",
      "Validation SMAPE Score: 53.2827%\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / (denominator + 1e-8)) * 100\n",
    "\n",
    "# --- LightGBM Model ---\n",
    "lgb_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**lgb_params)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_val, y_val)],\n",
    "          eval_metric='rmse',\n",
    "          callbacks=[lgb.early_stopping(100, verbose=True)])\n",
    "\n",
    "log_preds = model.predict(X_val)\n",
    "\n",
    "y_val_actual = np.expm1(y_val)\n",
    "final_preds = np.expm1(log_preds)\n",
    "\n",
    "smape_score = smape(y_val_actual, final_preds)\n",
    "print(f\"\\nValidation SMAPE Score: {smape_score:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- 1. Advanced Feature Engineering ---\n",
    "print(\"Running advanced feature engineering...\")\n",
    "\n",
    "# Extract Brand: A simple heuristic is to take the first 2-3 words after \"Item Name:\"\n",
    "def extract_brand(text):\n",
    "    try:\n",
    "        # Find text after \"Item Name:\" and before the next potential separator (like ',')\n",
    "        name_part = re.search(r'Item Name:\\s*([^,]+)', str(text)).group(1)\n",
    "        # Take the first two words as a potential brand\n",
    "        return ' '.join(name_part.split()[:2])\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "df['brand'] = df['catalog_content'].apply(extract_brand)\n",
    "\n",
    "# Convert the categorical brand names into numerical codes\n",
    "df['brand_code'], _ = pd.factorize(df['brand'])\n",
    "\n",
    "# (Assuming ipq, quantity_oz, and cleaned_text are already created)\n",
    "print(df[['brand', 'brand_code']].head())\n",
    "\n",
    "\n",
    "# --- 2. Improved Text Vectorization ---\n",
    "print(\"\\nRunning improved text vectorization with n-grams...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,      # Increased features\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)       # Captures two-word phrases\n",
    ")\n",
    "text_features = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Combine ALL features: TF-IDF + ipq + quantity_oz + brand_code\n",
    "numerical_features = df[['ipq', 'quantity_oz', 'brand_code']].values\n",
    "X = hstack([text_features, csr_matrix(numerical_features)])\n",
    "y = np.log1p(df['price'])\n",
    "print(f\"New feature matrix shape: {X.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Split Data ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# --- 4. Train with Updated Parameters ---\n",
    "print(\"\\nTraining LightGBM with updated parameters...\")\n",
    "lgb_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'rmse',\n",
    "    'n_estimators': 25000,      # More estimators\n",
    "    'learning_rate': 0.01,    # Slower learning rate\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**lgb_params)\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_val, y_val)],\n",
    "          eval_metric='rmse',\n",
    "          callbacks=[lgb.early_stopping(100, verbose=True)])\n",
    "\n",
    "# --- 5. Evaluate ---\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / (denominator + 1e-8)) * 100\n",
    "\n",
    "print(\"\\nEvaluating new model...\")\n",
    "log_preds = model.predict(X_val)\n",
    "y_val_actual = np.expm1(y_val)\n",
    "final_preds = np.expm1(log_preds)\n",
    "smape_score = smape(y_val_actual, final_preds)\n",
    "\n",
    "print(f\"\\nNew Validation SMAPE Score: {smape_score:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8465050,
     "sourceId": 13348022,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
